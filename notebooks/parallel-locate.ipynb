{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython2"
  },
  "name": "",
  "signature": "sha256:ba35e9c8803ba570f027c5967980b9102fb26acd83b3dc0aa64f42182eb5a516"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Parallelized Feature Location using IPython Parallel\n",
      "\n",
      "Feature-finding can easily be parallelized: each frame an independent task, and the tasks can be divided among the available CPUs. IPython parallel makes this very straightforward.\n",
      "\n",
      "It is simplest to try this on the CPUs of the local machine. To do this from an IPython notebook, go to File > Open, and click the \"Clusters\" tab. Fill in the \"engines\" field with the number of available CPUs (e.g., 4) and click start. Now you are running a cluster -- it's that easy. More information on IPython parallel is available in [this section of the IPython documentation](http://ipython.org/ipython-doc/stable/parallel/)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "view = client.load_balanced_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that there are four cores available."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "client[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "<DirectView [0, 1, 2, 3]>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use a little magic, ``%%px``, to import trackpy on all cores."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import trackpy as tp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Do the normal setup now, import trackpy normally and loading frames to analyze."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import trackpy as tp\n",
      "\n",
      "def gray(image):\n",
      "    return image[:, :, 0]\n",
      "\n",
      "frames = tp.ImageSequence('../sample_data/bulk_water/*.png', process_func=gray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define a function from ``locate`` with all the parameters specified, so the function's only argument is the image to be analyzed. We can map this function directly onto our collection of images. (This is a called \"currying\" a function, hence the choice of name.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curried_locate = lambda image: tp.locate(image, 13, invert=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "view.map(curried_locate, frames[:4])  # Optionally, prime each engine: make it set up FFTW."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "<AsyncMapResult: <lambda>>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compare the time it takes to locate features in the first ten images with and without parallelization."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "amr = view.map_async(curried_locate, frames[:32])\n",
      "amr.wait_interactive()\n",
      "results = amr.get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  32/32 tasks finished after    6 s\n",
        "done\n",
        "1 loops, best of 3: 6.89 s per loop\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "serial_result = map(curried_locate, frames[:32])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 13.7 s per loop\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}